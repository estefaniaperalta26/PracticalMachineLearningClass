{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02\n",
    "\n",
    "Estimate a classifier to predict churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "\n",
    "Customer Churn: losing/attrition of the customers from the company. Especially, the industries that the user acquisition is costly, it is crucially important for one company to reduce and ideally make the customer churn to 0 to sustain their recurring revenue. If you consider customer retention is always cheaper than customer acquisition and generally depends on the data of the user(usage of the service or product), it poses a great/exciting/hard problem for machine learning.\n",
    "\n",
    "## Data\n",
    "\n",
    "Dataset is from a telecom service provider where they have the service usage(international plan, voicemail plan, usage in daytime, usage in evenings and nights and so on) and basic demographic information(state and area code) of the user. For labels, I have a single data point whether the customer is churned out or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "from urllib import request\n",
    "response = request.urlopen('https://raw.githubusercontent.com/EricChiang/churn/master/data/churn.csv')\n",
    "raw_data = response.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert to numpy\n",
    "import numpy as np\n",
    "data = []\n",
    "for line in raw_data.splitlines()[1:]:\n",
    "    words = line.split(',')\n",
    "    data.append(words)\n",
    "data = np.array(data)\n",
    "column_names = raw_data.splitlines()[0].split(',')\n",
    "n_obs = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['State', 'Account Length', 'Area Code', 'Phone', \"Int'l Plan\", 'VMail Plan', 'VMail Message', 'Day Mins', 'Day Calls', 'Day Charge', 'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls', 'Night Charge', 'Intl Mins', 'Intl Calls', 'Intl Charge', 'CustServ Calls', 'Churn?']\n",
      "(3333, 21)\n"
     ]
    }
   ],
   "source": [
    "print(column_names)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['KS', '128', '415', '382-4657', 'no', 'yes', '25', '265.100000',\n",
       "        '110', '45.070000', '197.400000', '99', '16.780000', '244.700000',\n",
       "        '91', '11.010000', '10.000000', '3', '2.700000', '1', 'False.'],\n",
       "       ['OH', '107', '415', '371-7191', 'no', 'yes', '26', '161.600000',\n",
       "        '123', '27.470000', '195.500000', '103', '16.620000', '254.400000',\n",
       "        '103', '11.450000', '13.700000', '3', '3.700000', '1', 'False.']], \n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select only the numeric features\n",
    "X = data[:, [1,2,6,7,8,9,10]].astype(np.float)\n",
    "# Convert bools to floats\n",
    "X_ = (data[:, [4,5]] == 'no').astype(np.float)\n",
    "X = np.hstack((X, X_))\n",
    "Y = (data[:, -1] == 'True.').astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 128.  ,  415.  ,   25.  ,  265.1 ,  110.  ,   45.07,  197.4 ,\n",
       "           1.  ,    0.  ],\n",
       "       [ 107.  ,  415.  ,   26.  ,  161.6 ,  123.  ,   27.47,  195.5 ,\n",
       "           1.  ,    0.  ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of churn cases  483\n"
     ]
    }
   ],
   "source": [
    "print('Number of churn cases ', Y.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02.1\n",
    "\n",
    "Split the training set in two sets with 70% and 30% of the data, respectively.\n",
    "\n",
    "---\n",
    "Partir la base de datos es dos partes de 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2013, 9) (1320, 9)\n",
      "(2013,) (1320,)\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "random_sample = np.random.rand(n_obs)\n",
    "X_train, X_test = X[random_sample<0.6], X[random_sample>=0.6]\n",
    "Y_train, Y_test = Y[random_sample<0.6], Y[random_sample>=0.6]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Primera_X=X[0:2334]\n",
    "Primera_Y=Y[0:2334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2334, 9)\n",
      "(2334,)\n"
     ]
    }
   ],
   "source": [
    "print(Primera_X.shape)\n",
    "print(Primera_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Segunda_X=X[2334:3333]\n",
    "Segunda_Y=Y[2334:3333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 9)\n",
      "(999,)\n"
     ]
    }
   ],
   "source": [
    "print(Segunda_X.shape)\n",
    "print(Segunda_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02.2\n",
    "\n",
    "Train a logistic regression using the 70% set\n",
    "\n",
    "---\n",
    "Entrenar una regresion logistica usando la particion del 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02.3\n",
    "\n",
    "a) Create a confusion matrix using the prediction on the 30% set.\n",
    "\n",
    "b) Estimate the accuracy of the model in the 30% set\n",
    "\n",
    "---\n",
    "a) Estimar la matriz de confusion en la base del  30%.\n",
    "\n",
    "b) Calcular el poder de prediccion usando la "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1105,   26],\n",
       "       [ 165,   24]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85530303030303034"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y_test == y_pred).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set();\n",
    "cmap = mpl.colors.ListedColormap(sns.color_palette(\"hls\", 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 3)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = Segunda_X, Segunda_Y\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)\n",
    "X_reduced = pca.transform(X)\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(n_clusters=2, random_state=0) # Fixing the RNG in kmeans\n",
    "k_means.fit(X)\n",
    "y_pred = k_means.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[395 435]\n",
      " [106  63]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45845845845845845"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y == y_pred).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
